Help on method fit in module flaml.automl.automl:
fit(X_train=None, y_train=None, dataframe=None, label=None, metric=None, task: 'Optional[Union[str, Task]]' = None, n_jobs=None, log_file_name=None, estimator_list=None, time_budget=None, max_iter=None, sample=None, ensemble=None, eval_method=None, log_type=None, model_history=None, split_ratio=None, n_splits=None, log_training_metric=None, mem_thres=None, pred_time_limit=None, train_time_limit=None, X_val=None, y_val=None, sample_weight_val=None, groups_val=None, groups=None, verbose=None, retrain_full=None, split_type=None, learner_selector=None, hpo_method=None, starting_points=None, seed=None, n_concurrent_trials=None, keep_search_state=None, preserve_checkpoint=True, early_stop=None, force_cancel=None, append_log=None, auto_augment=None, min_sample_size=None, use_ray=None, use_spark=None, free_mem_ratio=0, metric_constraints=None, custom_hp=None, time_col=None, cv_score_agg_func=None, skip_transform=None, mlflow_logging=None, fit_kwargs_by_estimator=None, **fit_kwargs) method of flaml.automl.automl.AutoML instance
    Find a model for a given task.
    Args:
        X_train: A numpy array or a pandas dataframe of training data in
            shape (n, m). For time series forecsat tasks, the first column of X_train
            must be the timestamp column (datetime type). Other columns in
            the dataframe are assumed to be exogenous variables (categorical or numeric).
            When using ray, X_train can be a ray.ObjectRef.
        y_train: A numpy array or a pandas series of labels in shape (n, ).
        dataframe: A dataframe of training data including label column.
            For time series forecast tasks, dataframe must be specified and must have
            at least two columns, timestamp and label, where the first
            column is the timestamp column (datetime type). Other columns in
            the dataframe are assumed to be exogenous variables (categorical or numeric).
            When using ray, dataframe can be a ray.ObjectRef.
        label: A str of the label column name for, e.g., 'label';
            Note: If X_train and y_train are provided,
            dataframe and label are ignored;
            If not, dataframe and label must be provided.
        metric: A string of the metric name or a function,
            e.g., 'accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_weighted',
            'roc_auc_ovo_weighted', 'roc_auc_ovr_weighted', 'f1', 'micro_f1', 'macro_f1',
            'log_loss', 'mae', 'mse', 'r2', 'mape'. Default is 'auto'.
            If passing a customized metric function, the function needs to
            have the following input arguments:
    ```python
    def custom_metric(
        X_test, y_test, estimator, labels,
        X_train, y_train, weight_test=None, weight_train=None,
        config=None, groups_test=None, groups_train=None,
    ):
        return metric_to_minimize, metrics_to_log
    ```
            which returns a float number as the minimization objective,
            and a dictionary as the metrics to log. E.g.,
    ```python
    def custom_metric(
        X_val, y_val, estimator, labels,
        X_train, y_train, weight_val=None, weight_train=None,
        *args,
    ):
        from sklearn.metrics import log_loss
        import time
        start = time.time()
        y_pred = estimator.predict_proba(X_val)
        pred_time = (time.time() - start) / len(X_val)
        val_loss = log_loss(y_val, y_pred, labels=labels, sample_weight=weight_val)
        y_pred = estimator.predict_proba(X_train)
        train_loss = log_loss(y_train, y_pred, labels=labels, sample_weight=weight_train)
        alpha = 0.5
        return val_loss * (1 + alpha) - alpha * train_loss, {
            "val_loss": val_loss,
            "train_loss": train_loss,
            "pred_time": pred_time,
        }
    ```
        task: A string of the task type, e.g.,
            'classification', 'regression', 'ts_forecast_regression',
            'ts_forecast_classification', 'rank', 'seq-classification',
            'seq-regression', 'summarization', or an instance of Task class
        n_jobs: An integer of the number of threads for training | default=-1.
            Use all available resources when n_jobs == -1.
        log_file_name: A string of the log file name | default="". To disable logging,
            set it to be an empty string "".
        estimator_list: A list of strings for estimator names, or 'auto'.
            e.g., ```['lgbm', 'xgboost', 'xgb_limitdepth', 'catboost', 'rf', 'extra_tree']```.
        time_budget: A float number of the time budget in seconds.
            Use -1 if no time limit.
        max_iter: An integer of the maximal number of iterations.
            NOTE: when both time_budget and max_iter are unspecified,
            only one model will be trained per estimator.
        sample: A boolean of whether to sample the training data during
            search.
        ensemble: boolean or dict | default=False. Whether to perform
            ensemble after search. Can be a dict with keys 'passthrough'
            and 'final_estimator' to specify the passthrough and
            final_estimator in the stacker. The dict can also contain
            'n_jobs' as the key to specify the number of jobs for the stacker.
        eval_method: A string of resampling strategy, one of
            ['auto', 'cv', 'holdout'].
        split_ratio: A float of the valiation data percentage for holdout.
        n_splits: An integer of the number of folds for cross - validation.
        log_type: A string of the log type, one of
            ['better', 'all'].
            'better' only logs configs with better loss than previos iters
            'all' logs all the tried configs.
        model_history: A boolean of whether to keep the trained best
            model per estimator. Make sure memory is large enough if setting to True.
            Default value is False: best_model_for_estimator would return a
            untrained model for non-best learner.
        log_training_metric: A boolean of whether to log the training
            metric for each model.
        mem_thres: A float of the memory size constraint in bytes.
        pred_time_limit: A float of the prediction latency constraint in seconds.
            It refers to the average prediction time per row in validation data.
        train_time_limit: None or a float of the training time constraint in seconds.
        X_val: None or a numpy array or a pandas dataframe of validation data.
        y_val: None or a numpy array or a pandas series of validation labels.
        sample_weight_val: None or a numpy array of the sample weight of
            validation data of the same shape as y_val.
        groups_val: None or array-like | group labels (with matching length
            to y_val) or group counts (with sum equal to length of y_val)
            for validation data. Need to be consistent with groups.
        groups: None or array-like | Group labels (with matching length to
            y_train) or groups counts (with sum equal to length of y_train)
            for training data.
        verbose: int, default=3 | Controls the verbosity, higher means more
            messages.
        retrain_full: bool or str, default=True | whether to retrain the
            selected model on the full training data when using holdout.
            True - retrain only after search finishes; False - no retraining;
            'budget' - do best effort to retrain without violating the time
            budget.
        split_type: str or splitter object, default="auto" | the data split type.
            * A valid splitter object is an instance of a derived class of scikit-learn
            [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold)
            and have ``split`` and ``get_n_splits`` methods with the same signatures.
            Set eval_method to "cv" to use the splitter object.
            * Valid str options depend on different tasks.
            For classification tasks, valid choices are
                ["auto", 'stratified', 'uniform', 'time', 'group']. "auto" -> stratified.
            For regression tasks, valid choices are ["auto", 'uniform', 'time'].
                "auto" -> uniform.
            For time series forecast tasks, must be "auto" or 'time'.
            For ranking task, must be "auto" or 'group'.
        hpo_method: str, default="auto" | The hyperparameter
            optimization method. By default, CFO is used for sequential
            search and BlendSearch is used for parallel search.
            No need to set when using flaml's default search space or using
            a simple customized search space. When set to 'bs', BlendSearch
            is used. BlendSearch can be tried when the search space is
            complex, for example, containing multiple disjoint, discontinuous
            subspaces. When set to 'random', random search is used.
        starting_points: A dictionary or a str to specify the starting hyperparameter
            config for the estimators | default="data".
            If str:
                - if "data", use data-dependent defaults;
                - if "data:path" use data-dependent defaults which are stored at path;
                - if "static", use data-independent defaults.
            If dict, keys are the name of the estimators, and values are the starting
            hyperparamter configurations for the corresponding estimators.
            The value can be a single hyperparamter configuration dict or a list
            of hyperparamter configuration dicts.
            In the following code example, we get starting_points from the
            `automl` object and use them in the `new_automl` object.
            e.g.,
    ```python
    from flaml import AutoML
    automl = AutoML()
    X_train, y_train = load_iris(return_X_y=True)
    automl.fit(X_train, y_train)
    starting_points = automl.best_config_per_estimator
    new_automl = AutoML()
    new_automl.fit(X_train, y_train, starting_points=starting_points)
    ```
        seed: int or None, default=None | The random seed for hpo.
        n_concurrent_trials: [In preview] int, default=1 | The number of
            concurrent trials. When n_concurrent_trials > 1, flaml performes
            [parallel tuning](/docs/Use-Cases/Task-Oriented-AutoML#parallel-tuning)
            and installation of ray or spark is required: `pip install flaml[ray]`
            or `pip install flaml[spark]`. Please check
            [here](https://spark.apache.org/docs/latest/api/python/getting_started/install.html)
            for more details about installing Spark.
        keep_search_state: boolean, default=False | Whether to keep data needed
            for model search after fit(). By default the state is deleted for
            space saving.
        preserve_checkpoint: boolean, default=True | Whether to preserve the saved checkpoint
            on disk when deleting automl. By default the checkpoint is preserved.
        early_stop: boolean, default=False | Whether to stop early if the
            search is considered to converge.
        force_cancel: boolean, default=False | Whether to forcely cancel the PySpark job if overtime.
        append_log: boolean, default=False | Whether to directly append the log
            records to the input log file if it exists.
        auto_augment: boolean, default=True | Whether to automatically
            augment rare classes.
        min_sample_size: int, default=MIN_SAMPLE_TRAIN | the minimal sample
            size when sample=True.
        use_ray: boolean or dict.
            If boolean: default=False | Whether to use ray to run the training
            in separate processes. This can be used to prevent OOM for large
            datasets, but will incur more overhead in time.
            If dict: the dict contains the keywords arguments to be passed to
            [ray.tune.run](https://docs.ray.io/en/latest/tune/api_docs/execution.html).
        use_spark: boolean, default=False | Whether to use spark to run the training
            in parallel spark jobs. This can be used to accelerate training on large models
            and large datasets, but will incur more overhead in time and thus slow down
            training in some cases.
        free_mem_ratio: float between 0 and 1, default=0. The free memory ratio to keep during training.
        metric_constraints: list, default=[] | The list of metric constraints.
            Each element in this list is a 3-tuple, which shall be expressed
            in the following format: the first element of the 3-tuple is the name of the
            metric, the second element is the inequality sign chosen from ">=" and "<=",
            and the third element is the constraint value. E.g., `('precision', '>=', 0.9)`.
            Note that all the metric names in metric_constraints need to be reported via
            the metrics_to_log dictionary returned by a customized metric function.
            The customized metric function shall be provided via the `metric` key word argument
            of the fit() function or the automl constructor.
            Find examples in this [test](https://github.com/microsoft/FLAML/tree/main/test/automl/test_constraints.py).
            If `pred_time_limit` is provided as one of keyword arguments to fit() function or
            the automl constructor, flaml will automatically (and under the hood)
            add it as an additional element in the metric_constraints. Essentially 'pred_time_limit'
            specifies a constraint about the prediction latency constraint in seconds.
        custom_hp: dict, default=None | The custom search space specified by user
            Each key is the estimator name, each value is a dict of the custom search space for that estimator. Notice the
            domain of the custom search space can either be a value of a sample.Domain object.
    ```python
    custom_hp = {
        "transformer_ms": {
            "model_path": {
                "domain": "albert-base-v2",
            },
            "learning_rate": {
                "domain": tune.choice([1e-4, 1e-5]),
            }
        }
    }
    ```
        time_col: for a time series task, name of the column containing the timestamps. If not
            provided, defaults to the first column of X_train/X_val
        cv_score_agg_func: customized cross-validation scores aggregate function. Default to average metrics across folds. If specificed, this function needs to
            have the following input arguments:
            * val_loss_folds: list of floats, the loss scores of each fold;
            * log_metrics_folds: list of dicts/floats, the metrics of each fold to log.
            This function should return the final aggregate result of all folds. A float number of the minimization objective, and a dictionary as the metrics to log or None.
                E.g.,
    ```python
    def cv_score_agg_func(val_loss_folds, log_metrics_folds):
        metric_to_minimize = sum(val_loss_folds)/len(val_loss_folds)
        metrics_to_log = None
        for single_fold in log_metrics_folds:
            if metrics_to_log is None:
                metrics_to_log = single_fold
            elif isinstance(metrics_to_log, dict):
                metrics_to_log = {k: metrics_to_log[k] + v for k, v in single_fold.items()}
            else:
                metrics_to_log += single_fold
        if metrics_to_log:
            n = len(val_loss_folds)
            metrics_to_log = (
                {k: v / n for k, v in metrics_to_log.items()}
                if isinstance(metrics_to_log, dict)
                else metrics_to_log / n
            )
        return metric_to_minimize, metrics_to_log
    ```
        skip_transform: boolean, default=False | Whether to pre-process data prior to modeling.
        mlflow_logging: boolean, default=None | Whether to log the training results to mlflow.
            Default value is None, which means the logging decision is made based on
            AutoML.__init__'s mlflow_logging argument.
            This requires mlflow to be installed and to have an active mlflow run.
            FLAML will create nested runs.
        fit_kwargs_by_estimator: dict, default=None | The user specified keywords arguments, grouped by estimator name.
            For TransformersEstimator, available fit_kwargs can be found from
            [TrainingArgumentsForAuto](nlp/huggingface/training_args).
            e.g.,
    ```python
    fit_kwargs_by_estimator = {
        "transformer": {
            "output_dir": "test/data/output/",
            "fp16": False,
        },
        "tft": {
            "max_encoder_length": 1,
            "min_encoder_length": 1,
            "static_categoricals": [],
            "static_reals": [],
            "time_varying_known_categoricals": [],
            "time_varying_known_reals": [],
            "time_varying_unknown_categoricals": [],
            "time_varying_unknown_reals": [],
            "variable_groups": {},
            "lags": {},
        }
    }
    ```
        **fit_kwargs: Other key word arguments to pass to fit() function of
            the searched learners, such as sample_weight. Below are a few examples of
            estimator-specific parameters:
                period: int | forecast horizon for all time series forecast tasks.
                gpu_per_trial: float, default = 0 | A float of the number of gpus per trial,
                    only used by TransformersEstimator, XGBoostSklearnEstimator, and
                    TemporalFusionTransformerEstimator.
                group_ids: list of strings of column names identifying a time series, only
                    used by TemporalFusionTransformerEstimator, required for
                    'ts_forecast_panel' task. `group_ids` is a parameter for TimeSeriesDataSet object
                    from PyTorchForecasting.
                    For other parameters to describe your dataset, refer to
                    [TimeSeriesDataSet PyTorchForecasting](https://pytorch-forecasting.readthedocs.io/en/stable/api/pytorch_forecasting.data.timeseries.TimeSeriesDataSet.html).
                    To specify your variables, use `static_categoricals`, `static_reals`,
                    `time_varying_known_categoricals`, `time_varying_known_reals`,
                    `time_varying_unknown_categoricals`, `time_varying_unknown_reals`,
                    `variable_groups`. To provide more information on your data, use
                    `max_encoder_length`, `min_encoder_length`, `lags`.
                log_dir: str, default = "lightning_logs" | Folder into which to log results
                    for tensorboard, only used by TemporalFusionTransformerEstimator.
                max_epochs: int, default = 20 | Maximum number of epochs to run training,
                    only used by TemporalFusionTransformerEstimator.
                batch_size: int, default = 64 | Batch size for training model, only
                    used by TemporalFusionTransformerEstimator.
/tmp/ipykernel_555124/298486667.py:4: DeprecationWarning: The argument `by` for `LazyFrame.rolling` is deprecated. It has been renamed to `group_by`.
  .rolling(index_column="Event_Date", period="99y", by="CustomerID", closed="left")
/tmp/ipykernel_555124/2604062622.py:4: DeprecationWarning: The argument `by` for `LazyFrame.rolling` is deprecated. It has been renamed to `group_by`.
  .rolling(index_column="Event_Date", period="99y", by="CustomerID", closed="both")
/tmp/ipykernel_555124/4014605910.py:2: DeprecationWarning: The argument `columns` for `DataFrame.pivot` is deprecated. It has been renamed to `on`.
  df.pivot(
/tmp/ipykernel_555124/4014605910.py:24: DeprecationWarning: The argument `columns` for `DataFrame.pivot` is deprecated. It has been renamed to `on`.
  .pivot(
/tmp/ipykernel_555124/4014605910.py:49: DeprecationWarning: The argument `by` for `DataFrame.rolling` is deprecated. It has been renamed to `group_by`.
  .rolling(index_column="Event_Date", period="99y", by="CustomerID", closed="left")
/tmp/ipykernel_555124/298486667.py:4: DeprecationWarning: The argument `by` for `LazyFrame.rolling` is deprecated. It has been renamed to `group_by`.
  .rolling(index_column="Event_Date", period="99y", by="CustomerID", closed="left")
/tmp/ipykernel_555124/2604062622.py:4: DeprecationWarning: The argument `by` for `LazyFrame.rolling` is deprecated. It has been renamed to `group_by`.
  .rolling(index_column="Event_Date", period="99y", by="CustomerID", closed="both")
/tmp/ipykernel_555124/4014605910.py:2: DeprecationWarning: The argument `columns` for `DataFrame.pivot` is deprecated. It has been renamed to `on`.
  df.pivot(
/tmp/ipykernel_555124/4014605910.py:24: DeprecationWarning: The argument `columns` for `DataFrame.pivot` is deprecated. It has been renamed to `on`.
  .pivot(
/tmp/ipykernel_555124/4014605910.py:49: DeprecationWarning: The argument `by` for `DataFrame.rolling` is deprecated. It has been renamed to `group_by`.
  .rolling(index_column="Event_Date", period="99y", by="CustomerID", closed="left")
/tmp/ipykernel_555124/298486667.py:4: DeprecationWarning: The argument `by` for `LazyFrame.rolling` is deprecated. It has been renamed to `group_by`.
  .rolling(index_column="Event_Date", period="99y", by="CustomerID", closed="left")
/tmp/ipykernel_555124/2604062622.py:4: DeprecationWarning: The argument `by` for `LazyFrame.rolling` is deprecated. It has been renamed to `group_by`.
  .rolling(index_column="Event_Date", period="99y", by="CustomerID", closed="both")
/tmp/ipykernel_555124/4014605910.py:2: DeprecationWarning: The argument `columns` for `DataFrame.pivot` is deprecated. It has been renamed to `on`.
  df.pivot(
/tmp/ipykernel_555124/4014605910.py:24: DeprecationWarning: The argument `columns` for `DataFrame.pivot` is deprecated. It has been renamed to `on`.
  .pivot(
/tmp/ipykernel_555124/4014605910.py:49: DeprecationWarning: The argument `by` for `DataFrame.rolling` is deprecated. It has been renamed to `group_by`.
  .rolling(index_column="Event_Date", period="99y", by="CustomerID", closed="left")
[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.login() after wandb.init() has no effect.
2024/07/21 23:58:14 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '729ed9f4adbf43c09f06e9ad9a1f6976', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current lightgbm workflow
2024/07/21 23:58:15 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: "/home/howt/mambaforge/envs/py312syndata/lib/python3.12/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details."
2024/07/21 23:58:15 WARNING mlflow.lightgbm: Failed to log dataset information to MLflow Tracking. Reason: 'Dataset' object is not iterable
/home/howt/mambaforge/envs/py312syndata/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument
  _log_warning(f"Found `{alias}` in params. Will use it instead of argument")
/tmp/ipykernel_555124/298486667.py:4: DeprecationWarning: The argument `by` for `LazyFrame.rolling` is deprecated. It has been renamed to `group_by`.
  .rolling(index_column="Event_Date", period="99y", by="CustomerID", closed="left")
/tmp/ipykernel_555124/2604062622.py:4: DeprecationWarning: The argument `by` for `LazyFrame.rolling` is deprecated. It has been renamed to `group_by`.
  .rolling(index_column="Event_Date", period="99y", by="CustomerID", closed="both")
/tmp/ipykernel_555124/4014605910.py:2: DeprecationWarning: The argument `columns` for `DataFrame.pivot` is deprecated. It has been renamed to `on`.
  df.pivot(
/tmp/ipykernel_555124/4014605910.py:24: DeprecationWarning: The argument `columns` for `DataFrame.pivot` is deprecated. It has been renamed to `on`.
  .pivot(
/tmp/ipykernel_555124/4014605910.py:49: DeprecationWarning: The argument `by` for `DataFrame.rolling` is deprecated. It has been renamed to `group_by`.
  .rolling(index_column="Event_Date", period="99y", by="CustomerID", closed="left")
/tmp/ipykernel_555124/3838698074.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  X_train['Purchase_Policy'].replace(policy_cat_map)
/tmp/ipykernel_555124/673327588.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  X_train['Purchase_Policy'] = X_train['Purchase_Policy'].replace(policy_cat_map)
/tmp/ipykernel_555124/673327588.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  X_val['Purchase_Policy'] = X_val['Purchase_Policy'].replace(policy_cat_map)
[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.login() after wandb.init() has no effect.
[flaml.automl.logger: 07-22 00:01:34] {1680} INFO - task = classification
[flaml.automl.logger: 07-22 00:01:34] {1691} INFO - Evaluation method: cv
[flaml.automl.logger: 07-22 00:01:34] {1789} INFO - Minimizing error metric: 1-roc_auc_ovo
[flaml.automl.logger: 07-22 00:01:34] {1901} INFO - List of ML learners in AutoML Run: ['lgbm']
[flaml.automl.logger: 07-22 00:01:34] {2219} INFO - iteration 0, current learner lgbm
2024/07/22 00:01:49 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.8085131463835397\'.")]')]
[flaml.automl.logger: 07-22 00:01:48] {2345} INFO - Estimated sufficient time budget=10000s. Estimated necessary time budget=10s.
[flaml.automl.logger: 07-22 00:01:48] {2392} INFO -  at 14.4s,	estimator lgbm's best error=0.4945,	best estimator lgbm's best error=0.4945
[flaml.automl.logger: 07-22 00:01:48] {2219} INFO - iteration 1, current learner lgbm
2024/07/22 00:01:52 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.8085131463835397\'.")]')]
2024/07/22 00:01:55 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.8085131463835397\'.")]')]
2024/07/22 00:01:57 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.8085131463835397\'.")]')]
2024/07/22 00:02:00 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.8085131463835397\'.")]')]
[flaml.automl.logger: 07-22 00:02:01] {2392} INFO -  at 27.6s,	estimator lgbm's best error=0.4945,	best estimator lgbm's best error=0.4945
[flaml.automl.logger: 07-22 00:02:01] {2219} INFO - iteration 2, current learner lgbm
2024/07/22 00:02:02 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.26770501231052046\'.")]')]
2024/07/22 00:02:05 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.26770501231052046\'.")]')]
2024/07/22 00:02:08 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.26770501231052046\'.")]')]
2024/07/22 00:02:10 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.26770501231052046\'.")]')]
2024/07/22 00:02:13 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.26770501231052046\'.")]')]
[flaml.automl.logger: 07-22 00:02:15] {2392} INFO -  at 40.8s,	estimator lgbm's best error=0.4945,	best estimator lgbm's best error=0.4945
[flaml.automl.logger: 07-22 00:02:15] {2219} INFO - iteration 3, current learner lgbm
2024/07/22 00:02:16 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.9285002286474459\'.")]')]
2024/07/22 00:02:19 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.9285002286474459\'.")]')]
2024/07/22 00:02:21 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.9285002286474459\'.")]')]
2024/07/22 00:02:24 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.9285002286474459\'.")]')]
2024/07/22 00:02:26 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.9285002286474459\'.")]')]
2024/07/22 00:02:29 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.036870948924282464\'.")]')]
[flaml.automl.logger: 07-22 00:02:28] {2392} INFO -  at 54.3s,	estimator lgbm's best error=0.4945,	best estimator lgbm's best error=0.4945
[flaml.automl.logger: 07-22 00:02:28] {2219} INFO - iteration 4, current learner lgbm
2024/07/22 00:02:32 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.036870948924282464\'.")]')]
2024/07/22 00:02:34 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.036870948924282464\'.")]')]
2024/07/22 00:02:37 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.036870948924282464\'.")]')]
2024/07/22 00:02:40 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.036870948924282464\'.")]')]
[flaml.automl.logger: 07-22 00:02:41] {2392} INFO -  at 67.4s,	estimator lgbm's best error=0.4859,	best estimator lgbm's best error=0.4859
[flaml.automl.logger: 07-22 00:02:41] {2219} INFO - iteration 5, current learner lgbm
2024/07/22 00:02:42 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.9019070144825116\'.")]')]
2024/07/22 00:02:45 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.9019070144825116\'.")]')]
2024/07/22 00:02:47 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.9019070144825116\'.")]')]
2024/07/22 00:02:50 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.9019070144825116\'.")]')]
2024/07/22 00:02:53 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.9019070144825116\'.")]')]
[flaml.automl.logger: 07-22 00:02:55] {2392} INFO -  at 80.7s,	estimator lgbm's best error=0.4859,	best estimator lgbm's best error=0.4859
[flaml.automl.logger: 07-22 00:02:55] {2219} INFO - iteration 6, current learner lgbm
2024/07/22 00:02:56 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.03526861749513839\'.")]')]
2024/07/22 00:02:58 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.03526861749513839\'.")]')]
2024/07/22 00:03:01 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.03526861749513839\'.")]')]
2024/07/22 00:03:03 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.03526861749513839\'.")]')]
2024/07/22 00:03:06 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.03526861749513839\'.")]')]
2024/07/22 00:03:09 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.06384718203323846\'.")]')]
[flaml.automl.logger: 07-22 00:03:08] {2392} INFO -  at 93.9s,	estimator lgbm's best error=0.4760,	best estimator lgbm's best error=0.4760
[flaml.automl.logger: 07-22 00:03:08] {2219} INFO - iteration 7, current learner lgbm
2024/07/22 00:03:12 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.06384718203323846\'.")]')]
2024/07/22 00:03:14 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.06384718203323846\'.")]')]
2024/07/22 00:03:17 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.06384718203323846\'.")]')]
2024/07/22 00:03:19 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.06384718203323846\'.")]')]
[flaml.automl.logger: 07-22 00:03:21] {2392} INFO -  at 107.1s,	estimator lgbm's best error=0.4760,	best estimator lgbm's best error=0.4760
[flaml.automl.logger: 07-22 00:03:21] {2219} INFO - iteration 8, current learner lgbm
2024/07/22 00:03:22 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.930646190497405\'.")]')]
2024/07/22 00:03:25 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.930646190497405\'.")]')]
2024/07/22 00:03:27 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.930646190497405\'.")]')]
2024/07/22 00:03:30 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.930646190497405\'.")]')]
2024/07/22 00:03:33 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.930646190497405\'.")]')]
[flaml.automl.logger: 07-22 00:03:35] {2392} INFO -  at 120.8s,	estimator lgbm's best error=0.4760,	best estimator lgbm's best error=0.4760
[flaml.automl.logger: 07-22 00:03:35] {2219} INFO - iteration 9, current learner lgbm
2024/07/22 00:03:36 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.08497719668838281\'.")]')]
2024/07/22 00:03:38 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.08497719668838281\'.")]')]
2024/07/22 00:03:41 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.08497719668838281\'.")]')]
2024/07/22 00:03:43 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.08497719668838281\'.")]')]
2024/07/22 00:03:46 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.08497719668838281\'.")]')]
2024/07/22 00:03:49 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.9038613725964871\'.")]')]
[flaml.automl.logger: 07-22 00:03:48] {2392} INFO -  at 133.8s,	estimator lgbm's best error=0.4760,	best estimator lgbm's best error=0.4760
[flaml.automl.logger: 07-22 00:03:48] {2219} INFO - iteration 10, current learner lgbm
2024/07/22 00:03:52 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.9038613725964871\'.")]')]
2024/07/22 00:03:54 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.9038613725964871\'.")]')]
2024/07/22 00:03:57 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.9038613725964871\'.")]')]
2024/07/22 00:04:00 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.9038613725964871\'.")]')]
2024/07/22 00:04:03 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.9364631270378546\'.")]')]
[flaml.automl.logger: 07-22 00:04:02] {2392} INFO -  at 147.7s,	estimator lgbm's best error=0.4760,	best estimator lgbm's best error=0.4760
[flaml.automl.logger: 07-22 00:04:02] {2219} INFO - iteration 11, current learner lgbm
2024/07/22 00:04:05 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.9364631270378546\'.")]')]
2024/07/22 00:04:08 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.9364631270378546\'.")]')]
2024/07/22 00:04:10 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.9364631270378546\'.")]')]
2024/07/22 00:04:13 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.9364631270378546\'.")]')]
[flaml.automl.logger: 07-22 00:04:15] {2392} INFO -  at 161.2s,	estimator lgbm's best error=0.4760,	best estimator lgbm's best error=0.4760
[flaml.automl.logger: 07-22 00:04:15] {2219} INFO - iteration 12, current learner lgbm
2024/07/22 00:04:16 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.008096231785319104\'.")]')]
2024/07/22 00:04:19 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.008096231785319104\'.")]')]
2024/07/22 00:04:21 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.008096231785319104\'.")]')]
2024/07/22 00:04:24 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.008096231785319104\'.")]')]
2024/07/22 00:04:27 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.008096231785319104\'.")]')]
2024/07/22 00:04:29 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.06565057005888239\'.")]')]
[flaml.automl.logger: 07-22 00:04:28] {2392} INFO -  at 174.4s,	estimator lgbm's best error=0.4760,	best estimator lgbm's best error=0.4760
[flaml.automl.logger: 07-22 00:04:28] {2219} INFO - iteration 13, current learner lgbm
2024/07/22 00:04:32 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.06565057005888239\'.")]')]
2024/07/22 00:04:35 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.06565057005888239\'.")]')]
2024/07/22 00:04:37 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.06565057005888239\'.")]')]
[flaml.automl.logger: 07-22 00:04:41] {2392} INFO -  at 187.6s,	estimator lgbm's best error=0.4760,	best estimator lgbm's best error=0.4760
[flaml.automl.logger: 07-22 00:04:41] {2219} INFO - iteration 14, current learner lgbm
2024/07/22 00:04:40 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'learning_rate\' was already logged with value=\'0.09999999999999995\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.06565057005888239\'.")]')]
2024/07/22 00:04:42 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.9318698026248824\'.")]')]
2024/07/22 00:04:45 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.9318698026248824\'.")]')]
2024/07/22 00:04:48 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.9318698026248824\'.")]')]
2024/07/22 00:04:50 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.9318698026248824\'.")]')]
2024/07/22 00:04:53 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.9318698026248824\'.")]')]
[flaml.automl.logger: 07-22 00:04:55] {2392} INFO -  at 200.7s,	estimator lgbm's best error=0.4708,	best estimator lgbm's best error=0.4708
[flaml.automl.logger: 07-22 00:04:57] {2628} INFO - retrain lgbm for 2.7s
[flaml.automl.logger: 07-22 00:04:57] {2631} INFO - retrained model: LGBMClassifier(colsample_bytree=0.9318698026248824,
               learning_rate=0.018946909050488705, max_bin=127,
               min_child_samples=52, n_estimators=1, n_jobs=-1, num_leaves=9,
               reg_alpha=0.013137375807020256, reg_lambda=8.449943144714585,
               verbose=-1)
[flaml.automl.logger: 07-22 00:04:57] {1931} INFO - fit succeeded
[flaml.automl.logger: 07-22 00:04:57] {1932} INFO - Time taken to find the best model: 200.7075412273407
2024/07/22 00:04:56 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during lightgbm autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 994cdca36fe845d2a53170f5222fc051. Failed operations: [MlflowException("Changing param values is not allowed. Param with key=\'colsample_bytree\' was already logged with value=\'1.0\' for run ID=\'994cdca36fe845d2a53170f5222fc051\'. Attempted logging new value \'0.9318698026248824\'.")]')]
2024/07/22 00:05:40 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '1a26faff5a8b446e8af2569b3ad06ff5', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current lightgbm workflow
2024/07/22 00:05:41 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: "/home/howt/mambaforge/envs/py312syndata/lib/python3.12/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details."
2024/07/22 00:05:41 WARNING mlflow.lightgbm: Failed to log dataset information to MLflow Tracking. Reason: 'Dataset' object is not iterable
/home/howt/mambaforge/envs/py312syndata/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument
  _log_warning(f"Found `{alias}` in params. Will use it instead of argument")
/tmp/ipykernel_555124/298486667.py:4: DeprecationWarning: The argument `by` for `LazyFrame.rolling` is deprecated. It has been renamed to `group_by`.
  .rolling(index_column="Event_Date", period="99y", by="CustomerID", closed="left")
/tmp/ipykernel_555124/2604062622.py:4: DeprecationWarning: The argument `by` for `LazyFrame.rolling` is deprecated. It has been renamed to `group_by`.
  .rolling(index_column="Event_Date", period="99y", by="CustomerID", closed="both")
/tmp/ipykernel_555124/4014605910.py:2: DeprecationWarning: The argument `columns` for `DataFrame.pivot` is deprecated. It has been renamed to `on`.
  df.pivot(
/tmp/ipykernel_555124/4014605910.py:24: DeprecationWarning: The argument `columns` for `DataFrame.pivot` is deprecated. It has been renamed to `on`.
  .pivot(
/tmp/ipykernel_555124/4014605910.py:49: DeprecationWarning: The argument `by` for `DataFrame.rolling` is deprecated. It has been renamed to `group_by`.
  .rolling(index_column="Event_Date", period="99y", by="CustomerID", closed="left")
/tmp/ipykernel_555124/1418649706.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  X_train['Purchase_Policy'] = X_train['Purchase_Policy'].replace(policy_cat_map)
/tmp/ipykernel_555124/1418649706.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  X_val['Purchase_Policy'] = X_val['Purchase_Policy'].replace(policy_cat_map)
[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.login() after wandb.init() has no effect.
[LightGBM] [Warning] Unknown parameter: log_max_bin
[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
[LightGBM] [Warning] Unknown parameter: log_max_bin
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005464 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 514
[LightGBM] [Info] Number of data points in the train set: 449, number of used features: 16
[LightGBM] [Warning] Unknown parameter: log_max_bin
2024/07/22 00:06:18 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'd09cc30de0ab4ff2bc155c4cd0a9c7c3', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current lightgbm workflow
2024/07/22 00:06:19 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: "/home/howt/mambaforge/envs/py312syndata/lib/python3.12/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details."
2024/07/22 00:06:19 WARNING mlflow.lightgbm: Failed to log dataset information to MLflow Tracking. Reason: 'Dataset' object is not iterable
/home/howt/mambaforge/envs/py312syndata/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument
  _log_warning(f"Found `{alias}` in params. Will use it instead of argument")
[LightGBM] [Fatal] Length of labels differs from the length of #data
[LightGBM] [Warning] Unknown parameter: log_max_bin
[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
[LightGBM] [Warning] Unknown parameter: log_max_bin
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002434 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 514
[LightGBM] [Info] Number of data points in the train set: 449, number of used features: 16
[LightGBM] [Warning] Unknown parameter: log_max_bin
[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
[LightGBM] [Info] Start training from score 2.229399
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.login() after wandb.init() has no effect.
2024/07/22 00:06:33 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'f23ddf5de7474a9bb1f5c28ae0a0bc8b', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current lightgbm workflow
2024/07/22 00:06:34 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: "/home/howt/mambaforge/envs/py312syndata/lib/python3.12/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details."
2024/07/22 00:06:34 WARNING mlflow.lightgbm: Failed to log dataset information to MLflow Tracking. Reason: 'Dataset' object is not iterable
/home/howt/mambaforge/envs/py312syndata/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument
  _log_warning(f"Found `{alias}` in params. Will use it instead of argument")
2024/07/22 00:06:34 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: "/home/howt/mambaforge/envs/py312syndata/lib/python3.12/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details."
[LightGBM] [Warning] Unknown parameter: log_max_bin
[LightGBM] [Warning] Unknown parameter: log_max_bin
2024/07/22 00:09:17 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '8be2ed2c871e4b87b5af9b12e1b6bf63', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current lightgbm workflow
2024/07/22 00:09:17 WARNING mlflow.lightgbm: Unrecognized dataset type <class 'NoneType'>. Dataset logging skipped.
2024/07/22 00:09:17 WARNING mlflow.lightgbm: Failed to log dataset information to MLflow Tracking. Reason: 'Dataset' object is not iterable
[LightGBM] [Fatal] Label must be in [0, 6), but found 6 in label
/tmp/ipykernel_555124/502677079.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  X_train['Purchase_Policy'] = X_train['Purchase_Policy'].replace(policy_cat_map)
/tmp/ipykernel_555124/502677079.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
  X_val['Purchase_Policy'] = X_val['Purchase_Policy'].replace(policy_cat_map)
[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.login() after wandb.init() has no effect.
[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003650 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 525
[LightGBM] [Info] Number of data points in the train set: 449, number of used features: 20
[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
[LightGBM] [Info] Start training from score -0.930873
[LightGBM] [Info] Start training from score -1.278709
[LightGBM] [Info] Start training from score -1.750314
[LightGBM] [Info] Start training from score -2.888147
[LightGBM] [Info] Start training from score -2.928969
[LightGBM] [Info] Start training from score -3.111291
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024/07/22 00:10:34 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'bc4bdd514f52437ca7db22394d8f5c30', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current lightgbm workflow
2024/07/22 00:10:35 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: "/home/howt/mambaforge/envs/py312syndata/lib/python3.12/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details."
2024/07/22 00:10:35 WARNING mlflow.lightgbm: Failed to log dataset information to MLflow Tracking. Reason: 'Dataset' object is not iterable
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024/07/22 00:10:39 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: "/home/howt/mambaforge/envs/py312syndata/lib/python3.12/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details."
[flaml.automl.logger: 07-22 00:12:20] {1680} INFO - task = classification
[flaml.automl.logger: 07-22 00:12:20] {1691} INFO - Evaluation method: cv
[flaml.automl.logger: 07-22 00:12:20] {1789} INFO - Minimizing error metric: multi_logloss
[flaml.automl.logger: 07-22 00:12:20] {1901} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']
[flaml.automl.logger: 07-22 00:12:20] {2219} INFO - iteration 0, current learner lgbm
2024/07/22 00:12:20 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'befab41be9814d8e8bad3841ef7b2888', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current lightgbm workflow
[flaml.automl.logger: 07-22 00:14:04] {1680} INFO - task = classification
[flaml.automl.logger: 07-22 00:14:04] {1691} INFO - Evaluation method: cv
[flaml.automl.logger: 07-22 00:14:04] {1789} INFO - Minimizing error metric: multi_logloss
[flaml.automl.logger: 07-22 00:14:04] {1901} INFO - List of ML learners in AutoML Run: ['lgbm']
[flaml.automl.logger: 07-22 00:14:04] {2219} INFO - iteration 0, current learner lgbm
2024/07/22 00:14:04 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'e075329425a3499491d00c740a6d6128', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current lightgbm workflow
[flaml.automl.logger: 07-22 00:14:08] {1680} INFO - task = classification
[flaml.automl.logger: 07-22 00:14:08] {1691} INFO - Evaluation method: cv
[flaml.automl.logger: 07-22 00:14:08] {1789} INFO - Minimizing error metric: multi_logloss
[flaml.automl.logger: 07-22 00:14:08] {1901} INFO - List of ML learners in AutoML Run: ['lgbm']
[flaml.automl.logger: 07-22 00:14:08] {2219} INFO - iteration 0, current learner lgbm
2024/07/22 00:14:08 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'f40792bee5184aaa8169faef63c50a28', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current lightgbm workflow
[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.login() after wandb.init() has no effect.
Accuracy: 0.9488
Precision (per class): [0.91052632 0.97457627 1.         0.92307692 1.         0.95238095]
Recall (per class): [0.97740113 0.92       0.8974359  0.96       1.         1.        ]
F1 Score (per class): [0.94277929 0.94650206 0.94594595 0.94117647 1.         0.97560976]
Macro-Average Precision: 0.9601
Macro-Average Recall: 0.9591
Macro-Average F1 Score: 0.9587
Micro-Average Precision: 0.9488
Micro-Average Recall: 0.9488
Micro-Average F1 Score: 0.9488
Weighted-Average Precision: 0.9512
Weighted-Average Recall: 0.9488
Weighted-Average F1 Score: 0.9488
Confusion Matrix:
[[173   3   0   1   0   0]
 [  9 115   0   0   0   1]
 [  7   0  70   1   0   0]
 [  1   0   0  24   0   0]
 [  0   0   0   0  24   0]
 [  0   0   0   0   0  20]]
Classification Report:
              precision    recall  f1-score   support
           0       0.91      0.98      0.94       177
           1       0.97      0.92      0.95       125
           2       1.00      0.90      0.95        78
           3       0.92      0.96      0.94        25
           4       1.00      1.00      1.00        24
           5       0.95      1.00      0.98        20
    accuracy                           0.95       449
   macro avg       0.96      0.96      0.96       449
weighted avg       0.95      0.95      0.95       449
Accuracy: 0.9488
Precision (per class): [0.91052632 0.97457627 1.         0.92307692 1.         0.95238095]
Recall (per class): [0.97740113 0.92       0.8974359  0.96       1.         1.        ]
F1 Score (per class): [0.94277929 0.94650206 0.94594595 0.94117647 1.         0.97560976]
Macro-Average Precision: 0.9601
Macro-Average Recall: 0.9591
Macro-Average F1 Score: 0.9587
Micro-Average Precision: 0.9488
Micro-Average Recall: 0.9488
Micro-Average F1 Score: 0.9488
Weighted-Average Precision: 0.9512
Weighted-Average Recall: 0.9488
Weighted-Average F1 Score: 0.9488
Confusion Matrix:
[[173   3   0   1   0   0]
 [  9 115   0   0   0   1]
 [  7   0  70   1   0   0]
 [  1   0   0  24   0   0]
 [  0   0   0   0  24   0]
 [  0   0   0   0   0  20]]
Classification Report:
              precision    recall  f1-score   support
           0       0.91      0.98      0.94       177
           1       0.97      0.92      0.95       125
           2       1.00      0.90      0.95        78
           3       0.92      0.96      0.94        25
           4       1.00      1.00      1.00        24
           5       0.95      1.00      0.98        20
    accuracy                           0.95       449
   macro avg       0.96      0.96      0.96       449
weighted avg       0.95      0.95      0.95       449
Accuracy: 0.4070
Precision (per class): [0.49056604 0.34       0.11111111 0.         0.         0.        ]
Recall (per class): [0.65       0.34693878 0.05       0.         0.         0.        ]
F1 Score (per class): [0.55913978 0.34343434 0.06896552 0.         0.         0.        ]
Macro-Average Precision: 0.1569
Macro-Average Recall: 0.1745
Macro-Average F1 Score: 0.1619
Micro-Average Precision: 0.4070
Micro-Average Recall: 0.4070
Micro-Average F1 Score: 0.4070
Weighted-Average Precision: 0.3380
Weighted-Average Recall: 0.4070
Weighted-Average F1 Score: 0.3659
Confusion Matrix:
[[52 23  3  0  1  1]
 [26 17  3  3  0  0]
 [14  4  1  0  0  1]
 [ 7  2  1  0  0  1]
 [ 1  4  0  0  0  0]
 [ 6  0  1  0  0  0]]
Classification Report:
              precision    recall  f1-score   support
           0       0.49      0.65      0.56        80
           1       0.34      0.35      0.34        49
           2       0.11      0.05      0.07        20
           3       0.00      0.00      0.00        11
           4       0.00      0.00      0.00         5
           5       0.00      0.00      0.00         7
    accuracy                           0.41       172
   macro avg       0.16      0.17      0.16       172
weighted avg       0.34      0.41      0.37       172